{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The processed dataset:  [[  4.00000000e-01   6.00000000e-01   0.00000000e+00 ...,   2.14000000e+02\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " [  0.00000000e+00   2.00000000e-01   1.00000000e-01 ...,   3.00000000e+01\n",
      "    4.00000000e+00   0.00000000e+00]\n",
      " [ -5.00000000e-01   0.00000000e+00   0.00000000e+00 ...,   2.38000000e+02\n",
      "    6.00000000e+00   0.00000000e+00]\n",
      " ..., \n",
      " [ -1.00000000e-01   5.00000000e-01   0.00000000e+00 ...,   2.50000000e+02\n",
      "    3.00000000e+00   4.91100000e+04]\n",
      " [  1.00000000e-01   3.00000000e-01   1.00000000e-01 ...,   8.20000000e+01\n",
      "    4.00000000e+00   5.07740000e+04]\n",
      " [ -1.00000000e-01   7.00000000e-01   5.00000000e-01 ...,   2.70000000e+01\n",
      "    7.00000000e+00   6.23570000e+04]]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-afe7ed2acd95>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    105\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m \u001b[1;31m# Train the model using the training sets\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 107\u001b[1;33m \u001b[0mregr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCV\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    108\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m \u001b[1;31m# get the predictions on the training data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\PJMLL\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\base.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    510\u001b[0m         \u001b[0mn_jobs_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    511\u001b[0m         X, y = check_X_y(X, y, accept_sparse=['csr', 'csc', 'coo'],\n\u001b[1;32m--> 512\u001b[1;33m                          y_numeric=True, multi_output=True)\n\u001b[0m\u001b[0;32m    513\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    514\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0matleast_1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\PJMLL\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    519\u001b[0m     X = check_array(X, accept_sparse, dtype, order, copy, force_all_finite,\n\u001b[0;32m    520\u001b[0m                     \u001b[0mensure_2d\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_nd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_min_samples\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 521\u001b[1;33m                     ensure_min_features, warn_on_dtype, estimator)\n\u001b[0m\u001b[0;32m    522\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    523\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n",
      "\u001b[1;32mC:\\Users\\PJMLL\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    405\u001b[0m                              % (array.ndim, estimator_name))\n\u001b[0;32m    406\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 407\u001b[1;33m             \u001b[0m_assert_all_finite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    408\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    409\u001b[0m     \u001b[0mshape_repr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_shape_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\PJMLL\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[1;34m(X)\u001b[0m\n\u001b[0;32m     56\u001b[0m             and not np.isfinite(X).all()):\n\u001b[0;32m     57\u001b[0m         raise ValueError(\"Input contains NaN, infinity\"\n\u001b[1;32m---> 58\u001b[1;33m                          \" or a value too large for %r.\" % X.dtype)\n\u001b[0m\u001b[0;32m     59\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import pylab as P\n",
    "import numpy as np\n",
    "\n",
    "#model packages\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "#evaluate packages\n",
    "from sklearn.datasets import make_friedman1\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "#validation curve\n",
    "from sklearn.model_selection import validation_curve\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "# learning curve\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "dataset = pd.read_csv('popularitybot_datamodel.csv')\n",
    "dataset.head()\n",
    "dataset.describe()\n",
    "\n",
    "\n",
    "#pre-processing features\n",
    "language_content_score= dataset.language_content_score.values.reshape((len(dataset.language_content_score), 1))\n",
    "language_content_magnitude  = dataset.language_content_magnitude.values.reshape((len(dataset.language_content_magnitude), 1))\n",
    "language_title_score  = dataset.language_title_score.values.reshape((len(dataset.language_title_score), 1))\n",
    "language_title_magnitude  = dataset.language_title_magnitude.values.reshape((len(dataset.language_title_magnitude), 1))\n",
    "post_domain = dataset.post_domain.values.reshape((len(dataset.post_domain), 1))\n",
    "post_gilded  = dataset.post_gilded.values.reshape((len(dataset.post_gilded), 1))\n",
    "post_hide_score =  dataset.post_hide_score.values.reshape((len(dataset.post_hide_score), 1))\n",
    "post_subreddit =  dataset.post_subreddit.values.reshape((len(dataset.post_subreddit), 1))\n",
    "post_is_reddit_media_domain =  dataset.post_is_reddit_media_domain.values.reshape((len(dataset.post_is_reddit_media_domain), 1))\n",
    "post_num_comments =  dataset.post_num_comments.values.reshape((len(dataset.post_num_comments), 1))\n",
    "post_num_crossposts =  dataset.post_num_crossposts.values.reshape((len(dataset.post_num_crossposts), 1))\n",
    "post_over_18 =  dataset.post_over_18.values.reshape((len(dataset.post_over_18), 1))\n",
    "user_comment_karma =  dataset.user_comment_karma.values.reshape((len(dataset.user_comment_karma), 1))\n",
    "user_is_gold =  dataset.user_is_gold.values.reshape((len(dataset.user_is_gold), 1))\n",
    "user_is_mod =  dataset.user_is_mod.values.reshape((len(dataset.user_is_mod), 1))\n",
    "user_link_karma =  dataset.user_link_karma.values.reshape((len(dataset.user_link_karma), 1))\n",
    "user_verified =  dataset.user_verified.values.reshape((len(dataset.user_verified), 1))\n",
    "vision_blue =  dataset.vision_blue.values.reshape((len(dataset.vision_blue), 1))\n",
    "vision_green =  dataset.vision_green.values.reshape((len(dataset.vision_green), 1))\n",
    "vision_red =  dataset.vision_red.values.reshape((len(dataset.vision_red), 1))\n",
    "post_age =  dataset.post_age.values.reshape((len(dataset.post_age), 1))\n",
    "\n",
    "\n",
    "\n",
    "#hot encode categorical variable\n",
    "enc = preprocessing.OneHotEncoder()\n",
    "enc.fit(post_domain)\n",
    "transformed_post_domain  = enc.transform(post_domain).toarray()\n",
    "\n",
    "enc = preprocessing.OneHotEncoder()\n",
    "enc.fit(post_gilded)\n",
    "transformed_post_gilded  = enc.transform(post_gilded).toarray()\n",
    "\n",
    "enc = preprocessing.OneHotEncoder()\n",
    "enc.fit(post_hide_score)\n",
    "transformed_post_hide_score = enc.transform(post_hide_score).toarray()\n",
    "\n",
    "enc = preprocessing.OneHotEncoder()\n",
    "enc.fit(post_subreddit)\n",
    "transformed_post_subreddit = enc.transform(post_subreddit).toarray()\n",
    "\n",
    "enc = preprocessing.OneHotEncoder()\n",
    "enc.fit(post_is_reddit_media_domain)\n",
    "transformed_post_is_reddit_media_domain = enc.transform(post_is_reddit_media_domain).toarray()\n",
    "\n",
    "enc = preprocessing.OneHotEncoder()\n",
    "enc.fit(post_over_18)\n",
    "transformed_post_over_18 = enc.transform(post_over_18).toarray()\n",
    "\n",
    "enc = preprocessing.OneHotEncoder()\n",
    "enc.fit(user_is_gold)\n",
    "transformed_user_is_gold= enc.transform(user_is_gold).toarray()\n",
    "\n",
    "enc = preprocessing.OneHotEncoder()\n",
    "enc.fit(user_is_mod)\n",
    "transformed_user_is_mod = enc.transform(user_is_mod).toarray()\n",
    "\n",
    "enc = preprocessing.OneHotEncoder()\n",
    "enc.fit(user_verified)\n",
    "transformed_user_verified  = enc.transform(user_verified).toarray()\n",
    "\n",
    "\n",
    "# prepare datasets to be fed in the regression model\n",
    "#predict post_score given all other EV\n",
    "CV =  dataset.post_score.values.reshape((len(dataset.post_score), 1))\n",
    "data = np.concatenate((language_content_score,language_content_magnitude,language_title_score,language_title_magnitude,transformed_post_domain,transformed_post_gilded,transformed_post_hide_score,transformed_post_subreddit,transformed_post_is_reddit_media_domain,post_num_comments,post_num_crossposts,transformed_post_over_18,user_comment_karma,transformed_user_is_gold,transformed_user_is_mod,user_link_karma,transformed_user_verified,vision_blue,vision_green,vision_red,post_age,), axis=1)\n",
    "print(\"The processed dataset: \", np.concatenate((data, CV), axis=1))\n",
    "\n",
    "# Create linear regression object\n",
    "regr = linear_model.LinearRegression()\n",
    "\n",
    "# Train the model using the training sets\n",
    "regr.fit(data, CV)\n",
    "\n",
    "# get the predictions on the training data\n",
    "predicted_results = regr.predict(data)\n",
    "\n",
    "print(\"Results:\")\n",
    "# The coefficients (mis, b) of y = misxis + b\n",
    "print('Coefficients: \\n', regr.coef_)\n",
    "print('Intercept (b): \\n', regr.intercept_)\n",
    "\n",
    "print(\"Mean residual sum of squares = %.2f\"\n",
    "      % np.mean((regr.predict(data) - CV) ** 2))\n",
    "print('R2 = %.2f' % regr.score(data,CV))\n",
    "\n",
    "\n",
    "# to see how the residual errors behave\n",
    "residual_error = CV - predicted_results\n",
    "print(\"Mean of residuals =\", np.mean(residual_error))\n",
    "print(\"Standard deviation of residuals =\", np.std(residual_error))\n",
    "\n",
    "\n",
    "# distribution of residuals\n",
    "plt.figure(6)\n",
    "plt.hist(residual_error)\n",
    "plt.title(\"Distribution of residuals\")\n",
    "plt.xlabel(\"residual error\")\n",
    "plt.show()\n",
    "\n",
    "# distribution of residuals with normal distribution\n",
    "plt.figure(7)\n",
    "n, bins, patches = plt.hist(residual_error, 10, normed=1,  alpha = 0.5)\n",
    "y_pdf = P.normpdf(bins, np.mean(residual_error), np.std(residual_error))\n",
    "l = P.plot(bins, y_pdf, 'k--', linewidth=1.5)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#calculating 10 fold corss validation results\n",
    "kf = KFold(len(CV), n_folds=10, shuffle=True, random_state=0)\n",
    "scores = cross_val_score(model, data, CV, scoring = 'mean_squared_error', cv=kf)\n",
    "print(\"MSE of every fold with K=10: \", abs(scores))\n",
    "print(\"Mean of 10-fold cross-validated MSE: %0.2f (+/- %0.2f)\" % (abs(scores.mean()), scores.std() * 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
